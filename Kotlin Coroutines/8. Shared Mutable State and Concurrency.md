# Shared Mutable State and Concurrency

- Coroutine들은 `Dispatchers.Default`와 같은 multi-threaded dispatcher를 사용해 병렬적으로 수행될 수 있다.  
  하지만 모든 동시성 문제도 함께 안고 간다. 그중 가장 큰 문제점은 공유되는 가변 상태(shared mutable state)에 대한 접근을 동기화하는 것이다.  
  이를 해결하기 위해 coroutine이 선택한 방법은 multi-thread와 비슷한 것도 있지만, coroutine에 unique한 것도 있다.

## The Problem

- 동일한 동작을 1000번 수행하는 coroutine을 100개 실행시켜보자.

```kt
suspend fun massiveRun(action: suspend() -> Unit) {
	val n = 100
	val k = 1000
	val time = measureTimeMillis {
		coroutineScope {
			repeat(n) {
				launch {
					repeat(k) { action() }
				}
			}
		}
	}
	println("Completed ${n * k} actions in $time ms")
}

var counter = 0

fun main() = runBlocking {
	withContext(Dispatchers.Default) {
		massiveRun {
			counter++
		}
	}
	println("Counter = $counter")
}
```

- 위 코드는 절대 counter값이 100000에 도달하지 않는다. 이론 상으로라면 `1000 * 100 = 100000`이어야 하는데, 왜 그럴까?  
  바로 100개의 coroutine들이 여러개의 thread에서 동기화 없이 counter 변수에 동시에 접근하기 때문이다.

---

## Volatiles are no of help

- 변수를 volatile 키워드를 적용한 채 선언하면, 이 문제가 해결될 것이라는 잘못 알려진 상식이 있다.  
  실제로 아래 코드를 실행해 봐도, counter는 절대 100000에 도달하지 못한다.

```kt
@Volatile
var counter = 0

fun main() = runBlocking {
	withContext(Dispatchers.Default) {
		massiveRun {
			counter++
		}
	}
	println("Counter = $counter")
}
```

- 위 코드는 counter에 `@Volatile`이 적용되지 않은 코드보다 수행 시간은 길지만, 역시 counter는 100000에 도달하지 못한다.  
  이는 volatile이 선형적인(linearizable, atomic) read, write 연산에 대한 순서는 보장하지만, 위 코드에서 발생한  
  increment 등의 더 큰 action에 대한 atomicity(원자성)은 보장하지 않기 때문이다.

---

## Thread-Safe Data Structures

- Thread와 Coroutine의 동시성 문제를 모두 해결할 수 있는 가장 일반적인 해결책으로 thread-safe(synchronized, atomic, linearizable)한  
  자료구조를 사용할 수 있다. 이 자료구조는 공유 상태(shared state)에 대한 연산을 모두 동기화해준다.

- 위 예시에서의 counter 변수에 대해서는 `AtomicInteger` 클래스를 사용할 수 있다.

```kt
var counter = AtomicInteger()

fun main() = runBlocking {
	withContext(Dispatchers.Default) {
		massiveRun {
			counter.incrementAndGet()
		}
	}
	println("Counter = $counter")
}
```

- `AtomicInteger`를 사용하는 것은 이 문제에 대한 해결책 중 하나다. 이렇게 thread-safety를 보장하는 자료구조를 사용하는 것은 일반적인 counter연산,  
  컬렉션, queue 등의 자료구조에 대한 기본적인 연산에 대한 동기화를 수행할 수 있다. 하지만 복잡한 state나 복잡한 연산을 수행할 때 쉽게 thread-safe하게  
  만들기가 꽤나 까다롭다.

---

## Thread Confinement Fine-Grained

- _Thread confinement_ 는 shared mutable state에 접근하는 것들이 하나의 thread에 국한되어있을 때 shared mutable state에 대한  
  문제를 해결하려는 전략이다. 주로 모든 UI 상태(state)가 하나의 event-dispatch/application thread를 사용하는 UI 애플리케이션에서 사용한다.  
  Single-threaded context를 사용해 coroutine을 실행하는 것은 아주 쉽다.

```kt
suspend fun massiveRun(action: suspend () -> Unit) {
	val n = 100  // number of coroutines to launch
	val k = 1000 // times an action is repeated by each coroutine
	val time = measureTimeMillis {
		coroutineScope { // scope for coroutines
			repeat(n) {
				launch {
					repeat(k) { action() }
				}
			}
		}
	}
	println("Completed ${n * k} actions in $time ms")
}

val counterContext = newSingleThreadContext("CounterContext")
var counter = 0

fun main() = runBlocking {
	withContext(Dispatchers.Default) {
		massiveRun {
			withContext(counterContext) {
				counter++
			}
		}
	}
	println("Counter = $counter")
}
```

- 위 코드는 수행되는데 시간이 꽤나 걸린다. 이는 _fine-grained_ thread confinement를 수행하기 때문인데, 즉 counter변수에 대한  
  각각의 increment 작업은 multi-thread로 동작하는 `Dispatchers.Default` context에서 single-thread를 사용하는  
  `withContext(counterContext)`로 switching되기 때문이다.

---

## Thread Confinement Coarse-Grained

- 실제 상황에서 thread confinement는 하나의 큰 단위로 수행된다. 여기서 _큰 단위_ 를 예로 들어보면, state를 갱신하는 비즈니스 로직을 예로 들  
  수 있고, 이 비즈니스 로직을 1개 thread에 국한(confine) 시킴으로서 thread confinement를 수행할 수 있다.

- 아래 예시 코드는 각 coroutine을 single-threaded context에서 수행한다.

```kt
suspend fun massiveRun(action: suspend () -> Unit) {
	val n = 100  // number of coroutines to launch
	val k = 1000 // times an action is repeated by each coroutine
	val time = measureTimeMillis {
		coroutineScope { // scope for coroutines
			repeat(n) {
				launch {
					repeat(k) { action() }
				}
			}
		}
	}
	println("Completed ${n * k} actions in $time ms")
}

val counterContext = newSingleThreadContext("CounterContext")
var counter = 0

fun main() = runBlocking {
	withContext(counterContext) {
		massiveRun { counter++ }
	}
	println("Counter = $counter")
}
```

- 위 코드는 정확하기도 하지만 fine-grained thread confinement보다 훨씬 더 빠르게 수행된다.

---

## Mutual Exclusion

- Mutual exclusion(상호 배제)을 사용하는 전략은 shared state에 대한 모든 변경 시도를 절대로 동시적으로 수행되지 않는 _critical section_ 으로  
  보호하는 것이다. Blocking code에서는 보통 `synchronized`나 `ReentrantLock`을 이를 위해 사용한다. Coroutine에서는 이를 위해 `Mutex`라는  
  클래스를 지원한다. `Mutex`는 *critical section*에 대한 lock, unlock을 위한 함수들을 제공한다. Blocking code의 대안과 `Mutex`의  
  주요한 차이점 중 하나로 `Mutex.lock()`이 suspending function이라는 점이 있다. 즉, thread를 block하지 않는다.

- 또한 추가적으로 `Mutex.lock() ... try { ..} finally { mutex.unlock() }`을 더욱 편리하게 사용할 수 있게 해주는  
  `withLock()` 확장 함수도 있다.

```kt
suspend fun massiveRun(action: suspend () -> Unit) {
	val n = 100  // number of coroutines to launch
	val k = 1000 // times an action is repeated by each coroutine
	val time = measureTimeMillis {
		coroutineScope { // scope for coroutines
			repeat(n) {
				launch {
					repeat(k) { action() }
				}
			}
		}
	}
	println("Completed ${n * k} actions in $time ms")
}

val mutex = Mutex()
var counter = 0

fun main() = runBlocking {
	withContext(Dispatchers.Default) {
		massiveRun {
			mutex.withLock { counter++ }
		}
	}
	println("Counter = $counter")
}
```

- 위 예시 코드에서의 locking은 fine-grained 방식이므로 비용이 꽤나 든다. 하지만 `Mutex`를 사용하는 것은 shared state를 주기적으로 변경해야  
  하지만, 해당 state를 보관할 thread를 선택하기 어려울 때 충분히 사용할 만한 방법이다.

---
